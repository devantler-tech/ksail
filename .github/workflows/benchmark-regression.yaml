name: Benchmark Regression

on:
  pull_request:
    paths:
      - "**/*.go"
      - "go.mod"
      - "go.sum"

env:
  GOPROXY: "https://proxy.golang.org|direct"

concurrency:
  group: "benchmark-${{ github.workflow }}-${{ github.ref }}"
  cancel-in-progress: true

permissions: {}

jobs:
  benchmark:
    name: ðŸ“Š Benchmark (${{ matrix.branch }})
    runs-on: ubuntu-latest
    permissions:
      contents: read
    strategy:
      matrix:
        branch: [pr, main]
    steps:
      - name: ðŸ“„ Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          ref: ${{ matrix.branch == 'main' && 'main' || github.event.pull_request.head.sha }}
          persist-credentials: false

      - name: âš™ï¸ Setup Go
        uses: actions/setup-go@7a3fe6cf4cb3a834922a1244abfce67bcef6a0c5 # v6.2.0
        with:
          go-version-file: go.mod

      - name: ðŸ” Discover benchmark packages
        id: discover
        shell: bash
        run: |
          set -euo pipefail
          pkgs=$(grep -rl '^func Benchmark' --include='*_test.go' . \
            | xargs -I{} dirname {} \
            | sort -u || true)
          if [ -z "$pkgs" ]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
          else
            {
              echo "skip=false"
              echo "packages<<EOF"
              echo "$pkgs"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          fi

      - name: ðŸƒ Run benchmarks
        if: steps.discover.outputs.skip == 'false'
        shell: bash
        env:
          PACKAGES: ${{ steps.discover.outputs.packages }}
        run: |
          set -euo pipefail
          echo "$PACKAGES" \
            | xargs go test -bench=. -benchmem -count=5 -benchtime=1s -run='^$' -timeout=30m \
            | tee "$RUNNER_TEMP/bench.txt"

      - name: ðŸ“¤ Upload results
        if: steps.discover.outputs.skip == 'false'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: bench-${{ matrix.branch }}
          path: ${{ runner.temp }}/bench.txt
          retention-days: 1

  compare:
    name: ðŸ“Š Compare & Report
    needs: benchmark
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: âš™ï¸ Setup Go
        uses: actions/setup-go@7a3fe6cf4cb3a834922a1244abfce67bcef6a0c5 # v6.2.0
        with:
          go-version: stable

      - name: ðŸ“¦ Install benchstat
        run: go install golang.org/x/perf/cmd/benchstat@latest

      - name: ðŸ“¥ Download results
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          path: ${{ runner.temp }}/benchmarks

      - name: ðŸ“Š Compare benchmarks
        id: benchstat
        run: |
          main_file="${RUNNER_TEMP}/benchmarks/bench-main/bench.txt"
          pr_file="${RUNNER_TEMP}/benchmarks/bench-pr/bench.txt"

          if [ ! -f "$main_file" ] || [ ! -f "$pr_file" ]; then
            echo "result=No benchmark results to compare (no benchmarks found)." >> "$GITHUB_OUTPUT"
            exit 0
          fi

          result=$(benchstat "$main_file" "$pr_file" 2>&1) || true
          {
            echo "result<<BENCHSTAT_EOF"
            echo "$result"
            echo "BENCHSTAT_EOF"
          } >> "$GITHUB_OUTPUT"

      - name: ðŸ’¬ Post benchmark comparison
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const body = `## ðŸ“Š Benchmark Regression Report

            <details>
            <summary>Benchmark comparison (main vs PR)</summary>

            \`\`\`
            ${process.env.BENCHSTAT_RESULT}
            \`\`\`

            </details>

            ### How to interpret

            - **sec/op**: Time per operation (lower is better)
            - **B/op**: Bytes allocated per operation (lower is better)
            - **allocs/op**: Allocations per operation (lower is better)
            - **~**: No statistically significant change (p â‰¥ 0.05)
            - **p-value**: Statistical confidence; values below 0.05 indicate a significant change

            > Generated by the [Benchmark Regression](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) workflow. See [docs/BENCHMARK-REGRESSION.md](docs/BENCHMARK-REGRESSION.md) for details.
            `;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const marker = '## ðŸ“Š Benchmark Regression Report';
            const existing = comments.find(c => c.body.includes(marker));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }
        env:
          BENCHSTAT_RESULT: ${{ steps.benchstat.outputs.result }}
