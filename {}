package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewLogsCmd creates the workload logs command.
func NewLogsCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the logs command directly
	client := kubectl.NewClient(ioStreams)
	logsCmd := client.CreateLogsCommand(kubeconfigPath)

	return logsCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewScaleCmd creates the workload scale command.
func NewScaleCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the scale command directly
	client := kubectl.NewClient(ioStreams)
	scaleCmd := client.CreateScaleCommand(kubeconfigPath)

	return scaleCmd
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewDeploymentCmd creates the gen deployment command.
func NewDeploymentCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateDeploymentCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// createGenCmd is a helper that creates a gen command by calling the provided kubectl method.
func createGenCmd(
	_ *runtime.Runtime,
	createMethod func(*kubectl.Client) (*cobra.Command, error),
) *cobra.Command {
	client := kubectl.NewClientWithStdio()
	cmd, err := createMethod(client)
	cobra.CheckErr(err)

	return cmd
}

// NewGenCmd creates and returns the gen command group namespace.
func NewGenCmd(runtimeContainer *runtime.Runtime) *cobra.Command {
	cmd := &cobra.Command{
		Use:   "gen",
		Short: "Generate Kubernetes resource manifests",
		Long: "Generate Kubernetes resource manifests using kubectl create with --dry-run=client -o yaml. " +
			"The generated YAML is printed to stdout and can be redirected to a file using shell redirection (> file.yaml).",
		RunE: func(cmd *cobra.Command, _ []string) error {
			return cmd.Help()
		},
		SilenceUsage: true,
	}

	cmd.AddCommand(NewClusterRoleCmd(runtimeContainer))
	cmd.AddCommand(NewClusterRoleBindingCmd(runtimeContainer))
	cmd.AddCommand(NewConfigMapCmd(runtimeContainer))
	cmd.AddCommand(NewCronJobCmd(runtimeContainer))
	cmd.AddCommand(NewDeploymentCmd(runtimeContainer))
	cmd.AddCommand(NewHelmReleaseCmd(runtimeContainer))
	cmd.AddCommand(NewIngressCmd(runtimeContainer))
	cmd.AddCommand(NewJobCmd(runtimeContainer))
	cmd.AddCommand(NewNamespaceCmd(runtimeContainer))
	cmd.AddCommand(NewPodDisruptionBudgetCmd(runtimeContainer))
	cmd.AddCommand(NewPriorityClassCmd(runtimeContainer))
	cmd.AddCommand(NewQuotaCmd(runtimeContainer))
	cmd.AddCommand(NewRoleCmd(runtimeContainer))
	cmd.AddCommand(NewRoleBindingCmd(runtimeContainer))
	cmd.AddCommand(NewSecretCmd(runtimeContainer))
	cmd.AddCommand(NewServiceCmd(runtimeContainer))
	cmd.AddCommand(NewServiceAccountCmd(runtimeContainer))

	return cmd
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewPodDisruptionBudgetCmd creates the gen poddisruptionbudget command.
func NewPodDisruptionBudgetCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreatePodDisruptionBudgetCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewNamespaceCmd creates the gen namespace command.
func NewNamespaceCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateNamespaceCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewPriorityClassCmd creates the gen priorityclass command.
func NewPriorityClassCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreatePriorityClassCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewQuotaCmd creates the gen quota command.
func NewQuotaCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateQuotaCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewRoleBindingCmd creates the gen rolebinding command.
func NewRoleBindingCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateRoleBindingCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewServiceAccountCmd creates the gen serviceaccount command.
func NewServiceAccountCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateServiceAccountCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewRoleCmd creates the gen role command.
func NewRoleCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateRoleCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewConfigMapCmd creates the gen configmap command.
func NewConfigMapCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateConfigMapCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewJobCmd creates the gen job command.
func NewJobCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateJobCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewCronJobCmd creates the gen cronjob command.
func NewCronJobCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateCronJobCmd)
}
// Package gen provides the gen command namespace for generating Kubernetes resources.
//
// This package contains commands for generating Kubernetes resource manifests
// using kubectl create with --dry-run=client -o yaml, supporting various
// resource types including deployments, services, secrets, configmaps, and more.
package gen
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewServiceCmd creates the gen service command.
func NewServiceCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateServiceCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewSecretCmd creates the gen secret command.
func NewSecretCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateSecretCmd)
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewIngressCmd creates the gen ingress command.
func NewIngressCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateIngressCmd)
}
package gen_test

import (
	"testing"

	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload/gen"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/stretchr/testify/require"
)

func TestNewGenCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewGenCmd(rt)

	require.NotNil(t, cmd, "expected gen command to be created")
	require.Equal(t, "gen", cmd.Use, "expected command use to be 'gen'")
	require.NotEmpty(t, cmd.Short, "expected command to have short description")
	require.NotEmpty(t, cmd.Long, "expected command to have long description")
}

func TestNewGenCmd_HasSubcommands(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewGenCmd(rt)

	subcommands := cmd.Commands()
	require.NotEmpty(t, subcommands, "expected gen command to have subcommands")

	// Check for some expected subcommands
	subcommandNames := make(map[string]bool)
	for _, subcmd := range subcommands {
		subcommandNames[subcmd.Name()] = true
	}

	expectedSubcommands := []string{
		"namespace",
		"deployment",
		"service",
		"configmap",
		"secret",
		"job",
		"cronjob",
		"ingress",
		"role",
		"rolebinding",
		"clusterrole",
		"clusterrolebinding",
		"serviceaccount",
		"quota",
		"poddisruptionbudget",
		"priorityclass",
		"helmrelease",
	}

	for _, expected := range expectedSubcommands {
		require.True(t, subcommandNames[expected], "expected subcommand %q to be present", expected)
	}
}

func TestNewNamespaceCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewNamespaceCmd(rt)

	require.NotNil(t, cmd, "expected namespace command to be created")
	require.Equal(t, "namespace", cmd.Name(), "expected command name to be 'namespace'")
}

func TestNewDeploymentCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewDeploymentCmd(rt)

	require.NotNil(t, cmd, "expected deployment command to be created")
	require.Equal(t, "deployment", cmd.Name(), "expected command name to be 'deployment'")
}

func TestNewServiceCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewServiceCmd(rt)

	require.NotNil(t, cmd, "expected service command to be created")
	require.Equal(t, "service", cmd.Name(), "expected command name to be 'service'")
}

func TestNewConfigMapCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewConfigMapCmd(rt)

	require.NotNil(t, cmd, "expected configmap command to be created")
	require.Equal(t, "configmap", cmd.Name(), "expected command name to be 'configmap'")
}

func TestNewSecretCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewSecretCmd(rt)

	require.NotNil(t, cmd, "expected secret command to be created")
	require.Equal(t, "secret", cmd.Name(), "expected command name to be 'secret'")
}

func TestNewJobCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewJobCmd(rt)

	require.NotNil(t, cmd, "expected job command to be created")
	require.Equal(t, "job", cmd.Name(), "expected command name to be 'job'")
}

func TestNewCronJobCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewCronJobCmd(rt)

	require.NotNil(t, cmd, "expected cronjob command to be created")
	require.Equal(t, "cronjob", cmd.Name(), "expected command name to be 'cronjob'")
}

func TestNewIngressCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewIngressCmd(rt)

	require.NotNil(t, cmd, "expected ingress command to be created")
	require.Equal(t, "ingress", cmd.Name(), "expected command name to be 'ingress'")
}

func TestNewRoleCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewRoleCmd(rt)

	require.NotNil(t, cmd, "expected role command to be created")
	require.Equal(t, "role", cmd.Name(), "expected command name to be 'role'")
}

func TestNewRoleBindingCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewRoleBindingCmd(rt)

	require.NotNil(t, cmd, "expected rolebinding command to be created")
	require.Equal(t, "rolebinding", cmd.Name(), "expected command name to be 'rolebinding'")
}

func TestNewClusterRoleCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewClusterRoleCmd(rt)

	require.NotNil(t, cmd, "expected clusterrole command to be created")
	require.Equal(t, "clusterrole", cmd.Name(), "expected command name to be 'clusterrole'")
}

func TestNewClusterRoleBindingCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewClusterRoleBindingCmd(rt)

	require.NotNil(t, cmd, "expected clusterrolebinding command to be created")
	require.Equal(
		t,
		"clusterrolebinding",
		cmd.Name(),
		"expected command name to be 'clusterrolebinding'",
	)
}

func TestNewServiceAccountCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewServiceAccountCmd(rt)

	require.NotNil(t, cmd, "expected serviceaccount command to be created")
	require.Equal(t, "serviceaccount", cmd.Name(), "expected command name to be 'serviceaccount'")
}

func TestNewQuotaCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewQuotaCmd(rt)

	require.NotNil(t, cmd, "expected quota command to be created")
	require.Equal(t, "quota", cmd.Name(), "expected command name to be 'quota'")
}

func TestNewPodDisruptionBudgetCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewPodDisruptionBudgetCmd(rt)

	require.NotNil(t, cmd, "expected poddisruptionbudget command to be created")
	require.Equal(
		t,
		"poddisruptionbudget",
		cmd.Name(),
		"expected command name to be 'poddisruptionbudget'",
	)
}

func TestNewPriorityClassCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewPriorityClassCmd(rt)

	require.NotNil(t, cmd, "expected priorityclass command to be created")
	require.Equal(t, "priorityclass", cmd.Name(), "expected command name to be 'priorityclass'")
}

func TestNewHelmReleaseCmd(t *testing.T) {
	t.Parallel()

	rt := runtime.NewRuntime()
	cmd := gen.NewHelmReleaseCmd(rt)

	require.NotNil(t, cmd, "expected helmrelease command to be created")
	require.Equal(t, "helmrelease", cmd.Name(), "expected command name to be 'helmrelease'")
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewClusterRoleCmd creates the gen clusterrole command.
func NewClusterRoleCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateClusterRoleCmd)
}
package gen

import (
	"encoding/json"
	"errors"
	"fmt"
	"maps"
	"os"
	"slices"
	"strings"
	"time"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	yamlgenerator "github.com/devantler-tech/ksail/v5/pkg/io/generator/yaml"
	"github.com/devantler-tech/ksail/v5/pkg/utils/notify"
	"github.com/devantler-tech/ksail/v5/pkg/utils/timer"
	helmv2 "github.com/fluxcd/helm-controller/api/v2"
	"github.com/fluxcd/pkg/apis/meta"
	sourcev1 "github.com/fluxcd/source-controller/api/v1"
	"github.com/spf13/cobra"
	apiextensionsv1 "k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"sigs.k8s.io/yaml"
)

const (
	defaultInterval         = 1 * time.Minute
	defaultTimeout          = 5 * time.Minute
	expectedKindNameParts   = 2
	expectedNamespaceParts  = 2
	expectedDependencyParts = 2
	singleDependencyPart    = 1
)

const helmReleaseExamples = `  # Generate a HelmRelease with a chart from a HelmRepository source
  ksail workload gen helmrelease podinfo \
    --interval=10m \
    --source=HelmRepository/podinfo \
    --chart=podinfo \
    --chart-version=">4.0.0" \
    --export

  # Generate a HelmRelease with a chart from a GitRepository source
  ksail workload gen helmrelease podinfo \
    --interval=10m \
    --source=GitRepository/podinfo \
    --chart=./charts/podinfo \
    --export

  # Generate a HelmRelease with values from local YAML files
  ksail workload gen helmrelease podinfo \
    --source=HelmRepository/podinfo \
    --chart=podinfo \
    --values=./my-values1.yaml \
    --values=./my-values2.yaml \
    --export

  # Generate a HelmRelease with values from a Kubernetes secret
  ksail workload gen helmrelease podinfo \
    --source=HelmRepository/podinfo \
    --chart=podinfo \
    --values-from=Secret/my-secret-values \
    --export

  # Generate a HelmRelease with a custom release name
  ksail workload gen helmrelease podinfo \
    --release-name=podinfo-dev \
    --source=HelmRepository/podinfo \
    --chart=podinfo \
    --export

  # Generate a HelmRelease targeting another namespace
  ksail workload gen helmrelease podinfo \
    --target-namespace=test \
    --create-target-namespace=true \
    --source=HelmRepository/podinfo \
    --chart=podinfo \
    --export

  # Generate a HelmRelease using a chart reference
  ksail workload gen helmrelease podinfo \
    --namespace=default \
    --chart-ref=HelmChart/podinfo.flux-system \
    --export`

var (
	errInvalidFormat     = errors.New("invalid format")
	errInvalidKind       = errors.New("invalid kind")
	errInvalidDependency = errors.New("invalid depends-on format")
	errNotImplemented    = errors.New(
		"applying HelmRelease to cluster is not yet implemented, use --export flag to generate YAML",
	)
	errMissingSourceOrRef = errors.New(
		"either --source with --chart or --chart-ref must be specified",
	)
	errConflictingSource = errors.New("cannot specify both --source/--chart and --chart-ref")
)

// resourceReference represents a parsed Kubernetes resource reference.
type resourceReference struct {
	Kind      string
	Name      string
	Namespace string
}

// parseResourceReference parses a string in format "Kind/name" or "Kind/name.namespace".
func parseResourceReference(
	ref, defaultNamespace, errorContext string,
) (*resourceReference, error) {
	parts := strings.Split(ref, "/")
	if len(parts) != expectedKindNameParts {
		return nil, fmt.Errorf(
			"%w: %s, expected Kind/name or Kind/name.namespace",
			errInvalidFormat,
			errorContext,
		)
	}

	resRef := &resourceReference{
		Kind:      parts[0],
		Name:      parts[1],
		Namespace: defaultNamespace,
	}

	// Check if namespace is included in the name
	if strings.Contains(resRef.Name, ".") {
		nameParts := strings.SplitN(resRef.Name, ".", expectedNamespaceParts)
		resRef.Name = nameParts[0]
		resRef.Namespace = nameParts[1]
	}

	return resRef, nil
}

// validateKind checks if a kind is in the list of valid kinds.
func validateKind(kind string, validKinds []string, errorContext string) error {
	if slices.Contains(validKinds, kind) {
		return nil
	}

	return fmt.Errorf(
		"%w: %s kind %q, must be one of: %s",
		errInvalidKind,
		errorContext,
		kind,
		strings.Join(validKinds, ", "),
	)
}

// validateKindCaseInsensitive checks if a kind matches (case-insensitive)
// one of the valid kinds and returns the canonical form.
func validateKindCaseInsensitive(
	kind string,
	validKinds []string,
	errorContext string,
) (string, error) {
	for _, validKind := range validKinds {
		if strings.EqualFold(kind, validKind) {
			return validKind, nil
		}
	}

	return "", fmt.Errorf(
		"%w: %s kind %q, must be one of: %s",
		errInvalidKind,
		errorContext,
		kind,
		strings.Join(validKinds, ", "),
	)
}

// parseDependency parses a depends-on reference in format "name" or "namespace/name".
func parseDependency(dep string) (*helmv2.DependencyReference, error) {
	parts := strings.Split(dep, "/")
	if len(parts) == singleDependencyPart {
		// Same namespace
		return &helmv2.DependencyReference{
			Name: parts[0],
		}, nil
	}

	if len(parts) == expectedDependencyParts {
		// Different namespace
		return &helmv2.DependencyReference{
			Namespace: parts[0],
			Name:      parts[1],
		}, nil
	}

	return nil, fmt.Errorf("%w: %q, expected name or namespace/name", errInvalidDependency, dep)
}

// NewHelmReleaseCmd creates the workload gen helmrelease command.
func NewHelmReleaseCmd(_ *runtime.Runtime) *cobra.Command {
	cmd := &cobra.Command{
		Use:     "helmrelease [NAME]",
		Aliases: []string{"hr"},
		Short:   "Generate a HelmRelease resource",
		Long: "Generate a HelmRelease resource for a given HelmRepository, " +
			"GitRepository, Bucket, or chart reference source.",
		Example:      helmReleaseExamples,
		Args:         cobra.ExactArgs(1),
		RunE:         runHelmReleaseGen,
		SilenceUsage: true,
	}

	configureHelmReleaseFlags(cmd)

	return cmd
}

func runHelmReleaseGen(cmd *cobra.Command, args []string) error {
	tmr := timer.New()
	tmr.Start()

	cfg := readHelmReleaseFlags(cmd, args)

	err := validateHelmReleaseArgs(cfg.source, cfg.chart, cfg.chartRef, cfg.crdsPolicy)
	if err != nil {
		return err
	}

	helmRelease, err := buildHelmRelease(
		cfg.name,
		cfg.namespace,
		cfg.source,
		cfg.chart,
		cfg.chartVersion,
		cfg.chartRef,
		cfg.targetNamespace,
		cfg.storageNamespace,
		cfg.createNamespace,
		cfg.dependsOn,
		cfg.interval,
		cfg.timeout,
		cfg.values,
		cfg.valuesFrom,
		cfg.saName,
		cfg.crdsPolicy,
		cfg.kubeConfigSecretRef,
		cfg.releaseName,
	)
	if err != nil {
		return err
	}

	yaml, err := generateHelmReleaseYAML(helmRelease)
	if err != nil {
		return err
	}

	return outputHelmRelease(cmd, yaml, tmr)
}

func generateHelmReleaseYAML(helmRelease *helmv2.HelmRelease) (string, error) {
	generator := yamlgenerator.NewYAMLGenerator[helmv2.HelmRelease]()
	opts := yamlgenerator.Options{
		Output: "",
		Force:  false,
	}

	yaml, err := generator.Generate(*helmRelease, opts)
	if err != nil {
		return "", fmt.Errorf("failed to generate HelmRelease YAML: %w", err)
	}

	return yaml, nil
}

func outputHelmRelease(cmd *cobra.Command, yaml string, tmr timer.Timer) error {
	export, _ := cmd.Flags().GetBool("export")
	if export {
		_, err := fmt.Fprint(cmd.OutOrStdout(), yaml)
		if err != nil {
			return fmt.Errorf("failed to write YAML: %w", err)
		}
	} else {
		return errNotImplemented
	}

	outputTimer := helpers.MaybeTimer(cmd, tmr)

	notify.WriteMessage(notify.Message{
		Type:    notify.SuccessType,
		Content: "generated HelmRelease",
		Timer:   outputTimer,
		Writer:  cmd.OutOrStdout(),
	})

	return nil
}

func readHelmReleaseFlags(cmd *cobra.Command, args []string) helmReleaseConfig {
	name := args[0]
	namespace, _ := cmd.Flags().GetString("namespace")
	source, _ := cmd.Flags().GetString("source")
	chart, _ := cmd.Flags().GetString("chart")
	chartVersion, _ := cmd.Flags().GetString("chart-version")
	chartRef, _ := cmd.Flags().GetString("chart-ref")
	targetNamespace, _ := cmd.Flags().GetString("target-namespace")
	storageNamespace, _ := cmd.Flags().GetString("storage-namespace")
	createNamespace, _ := cmd.Flags().GetBool("create-target-namespace")
	dependsOn, _ := cmd.Flags().GetStringSlice("depends-on")
	interval, _ := cmd.Flags().GetDuration("interval")
	timeout, _ := cmd.Flags().GetDuration("timeout")
	values, _ := cmd.Flags().GetStringSlice("values")
	valuesFrom, _ := cmd.Flags().GetStringSlice("values-from")
	saName, _ := cmd.Flags().GetString("service-account")
	crdsPolicy, _ := cmd.Flags().GetString("crds")
	kubeConfigSecretRef, _ := cmd.Flags().GetString("kubeconfig-secret-ref")
	releaseName, _ := cmd.Flags().GetString("release-name")

	return newHelmReleaseConfig(name, namespace, source, chart, chartVersion, chartRef,
		targetNamespace, storageNamespace, createNamespace, dependsOn, interval, timeout,
		values, valuesFrom, saName, crdsPolicy, kubeConfigSecretRef, releaseName)
}

func newHelmReleaseConfig(name, namespace, source, chart, chartVersion, chartRef,
	targetNamespace, storageNamespace string, createNamespace bool, dependsOn []string,
	interval, timeout time.Duration, values, valuesFrom []string, saName, crdsPolicy,
	kubeConfigSecretRef, releaseName string,
) helmReleaseConfig {
	return helmReleaseConfig{
		name:                name,
		namespace:           namespace,
		source:              source,
		chart:               chart,
		chartVersion:        chartVersion,
		chartRef:            chartRef,
		targetNamespace:     targetNamespace,
		storageNamespace:    storageNamespace,
		createNamespace:     createNamespace,
		dependsOn:           dependsOn,
		interval:            interval,
		timeout:             timeout,
		values:              values,
		valuesFrom:          valuesFrom,
		saName:              saName,
		crdsPolicy:          crdsPolicy,
		kubeConfigSecretRef: kubeConfigSecretRef,
		releaseName:         releaseName,
	}
}

func configureHelmReleaseFlags(cmd *cobra.Command) {
	flags := cmd.Flags()

	// Required flags
	flags.String(
		"source",
		"",
		"source that contains the chart (HelmRepository/name, GitRepository/name, Bucket/name)",
	)
	flags.String("chart", "", "Helm chart name or path")
	flags.String("chart-ref", "", "Helm chart reference (HelmChart/name, OCIRepository/name)")

	// Optional flags
	flags.StringP("namespace", "n", "default", "namespace scope for the HelmRelease")
	flags.Duration("interval", defaultInterval, "reconciliation interval")
	flags.String("chart-version", "", "Helm chart version, accepts a semver range")
	flags.String("target-namespace", "", "namespace to target when performing operations")
	flags.String("storage-namespace", "", "namespace for Helm storage")
	flags.Bool("create-target-namespace", false, "create the target namespace if not present")
	flags.StringSlice("depends-on", nil, "HelmReleases that must be ready before this release")
	flags.Duration("timeout", defaultTimeout, "timeout for any individual Kubernetes operation")
	flags.StringSlice("values", nil, "local values YAML files")
	flags.StringSlice("values-from", nil, "values from ConfigMap or Secret")
	flags.String("service-account", "", "service account name to impersonate")
	flags.String("crds", "", "CRDs policy (Create, CreateReplace, Skip)")
	flags.String(
		"kubeconfig-secret-ref",
		"",
		"KubeConfig secret reference for remote reconciliation",
	)
	flags.String("release-name", "", "name used for the Helm release")
	flags.Bool("export", false, "export in YAML format to stdout")
}

func validateHelmReleaseArgs(source, chart, chartRef, crdsPolicy string) error {
	// Either source+chart or chartRef must be specified
	hasSource := source != "" && chart != ""
	hasChartRef := chartRef != ""

	if !hasSource && !hasChartRef {
		return errMissingSourceOrRef
	}

	if hasSource && hasChartRef {
		return errConflictingSource
	}

	// Validate CRDs policy if specified
	if crdsPolicy != "" {
		validPolicies := []string{"Create", "CreateReplace", "Skip"}

		err := validateKind(crdsPolicy, validPolicies, "crds policy")
		if err != nil {
			return err
		}
	}

	return nil
}

func buildHelmRelease(name, namespace, source, chart, chartVersion, chartRef,
	targetNamespace, storageNamespace string, createNamespace bool, dependsOn []string,
	interval, timeout time.Duration, values, valuesFrom []string, saName, crdsPolicy,
	kubeConfigSecretRef, releaseName string,
) (*helmv2.HelmRelease, error) {
	cfg := newHelmReleaseConfig(name, namespace, source, chart, chartVersion, chartRef,
		targetNamespace, storageNamespace, createNamespace, dependsOn, interval, timeout,
		values, valuesFrom, saName, crdsPolicy, kubeConfigSecretRef, releaseName)

	return buildHelmReleaseFromConfig(cfg)
}

func buildHelmReleaseFromConfig(cfg helmReleaseConfig) (*helmv2.HelmRelease, error) {
	helmRelease := createHelmReleaseBase(cfg)

	err := configureChartSource(helmRelease, cfg)
	if err != nil {
		return nil, err
	}

	configureOptionalFields(helmRelease, cfg)

	err = configureDependenciesAndValues(helmRelease, cfg)
	if err != nil {
		return nil, err
	}

	return helmRelease, nil
}

func createHelmReleaseBase(cfg helmReleaseConfig) *helmv2.HelmRelease {
	return &helmv2.HelmRelease{
		TypeMeta: metav1.TypeMeta{
			APIVersion: helmv2.GroupVersion.String(),
			Kind:       helmv2.HelmReleaseKind,
		},
		ObjectMeta: metav1.ObjectMeta{
			Name:      cfg.name,
			Namespace: cfg.namespace,
		},
		Spec: helmv2.HelmReleaseSpec{
			Interval: metav1.Duration{Duration: cfg.interval},
		},
	}
}

func configureChartSource(helmRelease *helmv2.HelmRelease, cfg helmReleaseConfig) error {
	if cfg.source != "" && cfg.chart != "" {
		err := setChartSpec(helmRelease, cfg.source, cfg.chart, cfg.chartVersion, cfg.namespace)
		if err != nil {
			return err
		}
	} else if cfg.chartRef != "" {
		err := setChartRef(helmRelease, cfg.chartRef, cfg.namespace)
		if err != nil {
			return err
		}
	}

	return nil
}

func configureOptionalFields(helmRelease *helmv2.HelmRelease, cfg helmReleaseConfig) {
	if cfg.releaseName != "" {
		helmRelease.Spec.ReleaseName = cfg.releaseName
	}

	if cfg.targetNamespace != "" {
		helmRelease.Spec.TargetNamespace = cfg.targetNamespace
	}

	if cfg.storageNamespace != "" {
		helmRelease.Spec.StorageNamespace = cfg.storageNamespace
	}

	if cfg.createNamespace {
		if helmRelease.Spec.Install == nil {
			helmRelease.Spec.Install = &helmv2.Install{}
		}

		helmRelease.Spec.Install.CreateNamespace = true
	}

	if cfg.timeout > 0 {
		helmRelease.Spec.Timeout = &metav1.Duration{Duration: cfg.timeout}
	}

	if cfg.saName != "" {
		helmRelease.Spec.ServiceAccountName = cfg.saName
	}

	setCRDsPolicy(helmRelease, cfg.crdsPolicy)

	if cfg.kubeConfigSecretRef != "" {
		helmRelease.Spec.KubeConfig = &meta.KubeConfigReference{
			SecretRef: &meta.SecretKeyReference{
				Name: cfg.kubeConfigSecretRef,
			},
		}
	}
}

func configureDependenciesAndValues(helmRelease *helmv2.HelmRelease, cfg helmReleaseConfig) error {
	err := setDependencies(helmRelease, cfg.dependsOn)
	if err != nil {
		return err
	}

	err = setValues(helmRelease, cfg.values, cfg.valuesFrom)
	if err != nil {
		return err
	}

	return nil
}

// mergeMaps merges two maps, with values from the second map taking precedence.
func mergeMaps(mapA, mapB map[string]any) map[string]any {
	out := make(map[string]any, len(mapA))

	maps.Copy(out, mapA)

	for key, val := range mapB {
		if valMap, ok := val.(map[string]any); ok {
			if bVal, ok := out[key]; ok {
				if bValMap, ok := bVal.(map[string]any); ok {
					out[key] = mergeMaps(bValMap, valMap)

					continue
				}
			}
		}

		out[key] = val
	}

	return out
}

// helmReleaseConfig holds all configuration for building a HelmRelease.
type helmReleaseConfig struct {
	name                string
	namespace           string
	source              string
	chart               string
	chartVersion        string
	chartRef            string
	targetNamespace     string
	storageNamespace    string
	createNamespace     bool
	dependsOn           []string
	interval            time.Duration
	timeout             time.Duration
	values              []string
	valuesFrom          []string
	saName              string
	crdsPolicy          string
	kubeConfigSecretRef string
	releaseName         string
}

// setChartSpec sets the chart specification for the HelmRelease.
func setChartSpec(
	helmRelease *helmv2.HelmRelease,
	source, chart, chartVersion, namespace string,
) error {
	sourceRef, err := parseResourceReference(source, namespace, "source")
	if err != nil {
		return err
	}

	// Validate source kind
	validSourceKinds := []string{
		sourcev1.HelmRepositoryKind,
		sourcev1.GitRepositoryKind,
		sourcev1.BucketKind,
	}

	err = validateKind(sourceRef.Kind, validSourceKinds, "source")
	if err != nil {
		return err
	}

	helmRelease.Spec.Chart = &helmv2.HelmChartTemplate{
		Spec: helmv2.HelmChartTemplateSpec{
			Chart: chart,
			SourceRef: helmv2.CrossNamespaceObjectReference{
				Kind:      sourceRef.Kind,
				Name:      sourceRef.Name,
				Namespace: sourceRef.Namespace,
			},
		},
	}

	if chartVersion != "" {
		helmRelease.Spec.Chart.Spec.Version = chartVersion
	}

	return nil
}

// setChartRef sets the chart reference for the HelmRelease.
func setChartRef(helmRelease *helmv2.HelmRelease, chartRef, namespace string) error {
	chartReference, err := parseResourceReference(chartRef, namespace, "chart-ref")
	if err != nil {
		return err
	}

	// Validate chartRef kind
	validChartRefKinds := []string{sourcev1.OCIRepositoryKind, sourcev1.HelmChartKind}

	err = validateKind(chartReference.Kind, validChartRefKinds, "chart-ref")
	if err != nil {
		return err
	}

	helmRelease.Spec.ChartRef = &helmv2.CrossNamespaceSourceReference{
		Kind:      chartReference.Kind,
		Name:      chartReference.Name,
		Namespace: chartReference.Namespace,
	}

	return nil
}

// setDependencies sets the dependencies for the HelmRelease.
func setDependencies(helmRelease *helmv2.HelmRelease, dependsOn []string) error {
	if len(dependsOn) == 0 {
		return nil
	}

	deps := []helmv2.DependencyReference{}

	for _, dep := range dependsOn {
		depRef, err := parseDependency(dep)
		if err != nil {
			return err
		}

		deps = append(deps, *depRef)
	}

	helmRelease.Spec.DependsOn = deps

	return nil
}

// setCRDsPolicy sets the CRDs policy for the HelmRelease.
func setCRDsPolicy(helmRelease *helmv2.HelmRelease, crdsPolicy string) {
	if crdsPolicy == "" {
		return
	}

	if helmRelease.Spec.Install == nil {
		helmRelease.Spec.Install = &helmv2.Install{}
	}

	helmRelease.Spec.Install.CRDs = helmv2.Create

	if helmRelease.Spec.Upgrade == nil {
		helmRelease.Spec.Upgrade = &helmv2.Upgrade{}
	}

	helmRelease.Spec.Upgrade.CRDs = helmv2.CRDsPolicy(crdsPolicy)
}

// setValues sets values from files and ConfigMaps/Secrets for the HelmRelease.
func setValues(helmRelease *helmv2.HelmRelease, values, valuesFrom []string) error {
	if len(values) > 0 {
		valuesMap, err := loadValuesFromFiles(values)
		if err != nil {
			return err
		}

		jsonData, err := json.Marshal(valuesMap)
		if err != nil {
			return fmt.Errorf("marshaling values to JSON: %w", err)
		}

		helmRelease.Spec.Values = &apiextensionsv1.JSON{Raw: jsonData}
	}

	if len(valuesFrom) > 0 {
		valuesRefs, err := parseValuesFrom(valuesFrom)
		if err != nil {
			return err
		}

		helmRelease.Spec.ValuesFrom = valuesRefs
	}

	return nil
}

// loadValuesFromFiles loads and merges values from multiple YAML files.
func loadValuesFromFiles(values []string) (map[string]any, error) {
	valuesMap := make(map[string]any)

	for _, vFile := range values {
		// #nosec G304 - file path is provided by user as intended
		data, err := os.ReadFile(vFile)
		if err != nil {
			return nil, fmt.Errorf("reading values file %s: %w", vFile, err)
		}

		jsonBytes, err := yaml.YAMLToJSON(data)
		if err != nil {
			return nil, fmt.Errorf("converting values to JSON from %s: %w", vFile, err)
		}

		jsonMap := make(map[string]any)

		err = json.Unmarshal(jsonBytes, &jsonMap)
		if err != nil {
			return nil, fmt.Errorf("unmarshaling values from %s: %w", vFile, err)
		}

		valuesMap = mergeMaps(valuesMap, jsonMap)
	}

	return valuesMap, nil
}

// parseValuesFrom parses values-from references.
func parseValuesFrom(valuesFrom []string) ([]helmv2.ValuesReference, error) {
	valuesRefs := []helmv2.ValuesReference{}

	for _, vf := range valuesFrom {
		vfRef, err := parseResourceReference(vf, "", "values-from")
		if err != nil {
			return nil, err
		}

		// Validate values-from kind
		validKinds := []string{"ConfigMap", "Secret"}

		canonicalKind, err := validateKindCaseInsensitive(vfRef.Kind, validKinds, "values-from")
		if err != nil {
			return nil, err
		}

		valuesRefs = append(valuesRefs, helmv2.ValuesReference{
			Kind: canonicalKind,
			Name: vfRef.Name,
		})
	}

	return valuesRefs, nil
}
package gen

import (
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewClusterRoleBindingCmd creates the gen clusterrolebinding command.
func NewClusterRoleBindingCmd(rt *runtime.Runtime) *cobra.Command {
	return createGenCmd(rt, (*kubectl.Client).CreateClusterRoleBindingCmd)
}
package workload

import (
	"fmt"
	"strings"

	v1alpha1 "github.com/devantler-tech/ksail/v5/pkg/apis/cluster/v1alpha1"
	"github.com/devantler-tech/ksail/v5/pkg/client/oci"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/devantler-tech/ksail/v5/pkg/svc/provisioner/registry"
	"github.com/devantler-tech/ksail/v5/pkg/utils/notify"
	"github.com/spf13/cobra"
)

// NewPushCmd creates the workload push command.
//
//nolint:funlen,cyclop // Cobra command RunE functions typically combine setup, validation, and execution
func NewPushCmd(_ *runtime.Runtime) *cobra.Command {
	var validate bool

	cmd := &cobra.Command{
		Use:          "push [source-directory]",
		Short:        "Package and push an OCI artifact to the local registry",
		Long:         "Build and push local workloads as an OCI artifact to the local registry.",
		Args:         cobra.MaximumNArgs(1),
		SilenceUsage: true,
	}

	cmd.RunE = func(cmd *cobra.Command, args []string) error {
		ctx, err := initCommandContext(cmd)
		if err != nil {
			return err
		}

		clusterCfg := ctx.ClusterCfg
		outputTimer := ctx.OutputTimer
		tmr := ctx.Timer

		localRegistryEnabled := clusterCfg.Spec.Cluster.LocalRegistry == v1alpha1.LocalRegistryEnabled
		gitOpsEngineConfigured := clusterCfg.Spec.Cluster.GitOpsEngine != v1alpha1.GitOpsEngineNone

		if !localRegistryEnabled || !gitOpsEngineConfigured {
			return errLocalRegistryRequired
		}

		// Determine the configured source directory for the repo name.
		// The repo name is always derived from the config's sourceDirectory,
		// ensuring artifacts are pushed to the repository Flux is watching.
		configSourceDir := strings.TrimSpace(clusterCfg.Spec.Workload.SourceDirectory)
		if configSourceDir == "" {
			configSourceDir = v1alpha1.DefaultSourceDirectory
		}

		repoName := registry.SanitizeRepoName(configSourceDir)

		// Use positional arg if provided to specify which directory to package,
		// otherwise fall back to the configured source directory.
		var sourceDir string
		if len(args) > 0 {
			sourceDir = args[0]
		} else {
			sourceDir = configSourceDir
		}

		artifactVersion := registry.DefaultLocalArtifactTag

		registryPort := clusterCfg.Spec.Cluster.LocalRegistryOpts.HostPort
		if registryPort == 0 {
			registryPort = v1alpha1.DefaultLocalRegistryPort
		}

		builder := oci.NewWorkloadArtifactBuilder()

		cmd.Println()
		notify.WriteMessage(notify.Message{
			Type:    notify.TitleType,
			Emoji:   "ðŸ“¦",
			Content: "Build and Push OCI Artifact...",
			Writer:  cmd.OutOrStdout(),
		})

		tmr.NewStage()

		// Validate if flag is set or config option is enabled
		shouldValidate := validate || clusterCfg.Spec.Workload.ValidateOnPush
		if shouldValidate {
			notify.WriteMessage(notify.Message{
				Type:    notify.ActivityType,
				Content: "validating manifests",
				Timer:   outputTimer,
				Writer:  cmd.OutOrStdout(),
			})

			err = runValidateCmd(
				cmd.Context(),
				cmd,
				[]string{sourceDir},
				true,  // skipSecrets
				true,  // strict
				true,  // ignoreMissingSchemas
				false, // verbose
			)
			if err != nil {
				return fmt.Errorf("validate manifests: %w", err)
			}

			notify.WriteMessage(notify.Message{
				Type:    notify.SuccessType,
				Content: "manifests validated",
				Timer:   outputTimer,
				Writer:  cmd.OutOrStdout(),
			})
		}

		notify.WriteMessage(notify.Message{
			Type:    notify.ActivityType,
			Content: "building oci artifact",
			Timer:   outputTimer,
			Writer:  cmd.OutOrStdout(),
		})

		notify.WriteMessage(notify.Message{
			Type:    notify.ActivityType,
			Content: "pushing oci artifact",
			Timer:   outputTimer,
			Writer:  cmd.OutOrStdout(),
		})

		_, err = builder.Build(cmd.Context(), oci.BuildOptions{
			Name:             repoName,
			SourcePath:       sourceDir,
			RegistryEndpoint: fmt.Sprintf("localhost:%d", registryPort),
			Repository:       repoName,
			Version:          artifactVersion,
			GitOpsEngine:     clusterCfg.Spec.Cluster.GitOpsEngine,
		})
		if err != nil {
			return fmt.Errorf("build and push oci artifact: %w", err)
		}

		notify.WriteMessage(notify.Message{
			Type:    notify.SuccessType,
			Content: "oci artifact pushed",
			Timer:   outputTimer,
			Writer:  cmd.OutOrStdout(),
		})

		return nil
	}

	cmd.Flags().BoolVar(&validate, "validate", false, "Validate manifests before pushing")

	return cmd
}
package workload_test

import (
	"bytes"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload"
)

const validNamespaceManifest = `apiVersion: v1
kind: Namespace
metadata:
  name: test-namespace
`

func TestNewValidateCmdHasCorrectDefaults(t *testing.T) {
	t.Parallel()

	cmd := workload.NewValidateCmd()

	if cmd.Use != "validate [PATH]" {
		t.Fatalf("expected Use to be 'validate [PATH]', got %q", cmd.Use)
	}

	if cmd.Short != "Validate Kubernetes manifests and kustomizations" {
		t.Fatalf(
			"expected Short description to be 'Validate Kubernetes manifests and kustomizations', got %q",
			cmd.Short,
		)
	}

	// Check default flag values
	skipSecrets, _ := cmd.Flags().GetBool("skip-secrets")
	if !skipSecrets {
		t.Fatal("expected skip-secrets to default to true")
	}

	strict, _ := cmd.Flags().GetBool("strict")
	if !strict {
		t.Fatal("expected strict to default to true")
	}

	ignoreMissingSchemas, _ := cmd.Flags().GetBool("ignore-missing-schemas")
	if !ignoreMissingSchemas {
		t.Fatal("expected ignore-missing-schemas to default to true")
	}

	verbose, _ := cmd.Flags().GetBool("verbose")
	if verbose {
		t.Fatal("expected verbose to default to false")
	}
}

func TestValidateCmdShowsHelp(t *testing.T) {
	t.Parallel()

	cmd := workload.NewValidateCmd()

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)
	cmd.SetArgs([]string{"--help"})

	err := cmd.Execute()
	if err != nil {
		t.Fatalf("expected no error, got %v", err)
	}

	helpText := output.String()
	if !strings.Contains(helpText, "Validate Kubernetes manifest") {
		t.Fatal("expected help text to contain 'Validate Kubernetes manifest'")
	}

	if !strings.Contains(helpText, "kubeconform") {
		t.Fatal("expected help text to mention kubeconform")
	}

	if !strings.Contains(helpText, "--skip-secrets") {
		t.Fatal("expected help text to include --skip-secrets flag")
	}

	if !strings.Contains(helpText, "--strict") {
		t.Fatal("expected help text to include --strict flag")
	}

	if !strings.Contains(helpText, "--ignore-missing-schemas") {
		t.Fatal("expected help text to include --ignore-missing-schemas flag")
	}

	if !strings.Contains(helpText, "--verbose") {
		t.Fatal("expected help text to include --verbose flag")
	}
}

func TestValidateCmdRejectsMultiplePaths(t *testing.T) {
	t.Parallel()

	cmd := workload.NewValidateCmd()

	// This test validates that the command rejects multiple path arguments
	cmd.SetArgs([]string{
		"/some/path1",
		"/some/path2",
	})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err := cmd.Execute()
	// We expect an error because multiple paths are not allowed
	if err == nil {
		t.Fatal("expected error for multiple paths")
	}

	// The error should be about too many arguments
	if !strings.Contains(err.Error(), "accepts at most 1 arg(s)") {
		t.Fatalf("expected error about too many arguments, got %v", err)
	}
}

func TestValidateCmdAcceptsSinglePath(t *testing.T) {
	t.Parallel()

	cmd := workload.NewValidateCmd()

	// This test validates that the command accepts a single path argument
	// It will fail during execution because the path doesn't exist, but that's expected
	cmd.SetArgs([]string{
		"/nonexistent/path",
	})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err := cmd.Execute()
	// We expect an error because the path doesn't exist
	if err == nil {
		t.Fatal("expected error for nonexistent path")
	}

	// The error should be about path access, not argument parsing
	if !strings.Contains(err.Error(), "access path") {
		t.Fatalf("expected error about path access, got %v", err)
	}
}

func TestValidateCmdWithValidManifest(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with a valid manifest
	tmpDir := t.TempDir()

	validManifest := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
  namespace: default
data:
  key: value
`
	manifestPath := filepath.Join(tmpDir, "valid-manifest.yaml")

	err := os.WriteFile(manifestPath, []byte(validManifest), 0o600)
	if err != nil {
		t.Fatalf("failed to write test manifest: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{tmpDir})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation to succeed, got error: %v", err)
	}
}

func TestValidateCmdWithInvalidManifest(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with an invalid manifest
	tmpDir := t.TempDir()

	// Create an invalid manifest
	invalidManifest := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
data: "invalid structure"
`
	manifestPath := filepath.Join(tmpDir, "invalid-manifest.yaml")

	err := os.WriteFile(manifestPath, []byte(invalidManifest), 0o600)
	if err != nil {
		t.Fatalf("failed to write test manifest: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{tmpDir})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err == nil {
		t.Fatal("expected validation to fail for invalid manifest")
	}
}

func TestValidateCmdWithKustomization(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with a valid kustomization
	tmpDir := t.TempDir()

	// Create a simple ConfigMap
	configMapYAML := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
  namespace: default
data:
  key: value
`

	err := os.WriteFile(filepath.Join(tmpDir, "configmap.yaml"), []byte(configMapYAML), 0o600)
	if err != nil {
		t.Fatalf("failed to write configmap: %v", err)
	}

	// Create a kustomization.yaml
	kustomizationYAML := `apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - configmap.yaml
`

	err = os.WriteFile(
		filepath.Join(tmpDir, "kustomization.yaml"),
		[]byte(kustomizationYAML),
		0o600,
	)
	if err != nil {
		t.Fatalf("failed to write kustomization: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{tmpDir})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation to succeed, got error: %v", err)
	}
}

func TestValidateCmdWithSkipSecretsFlag(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with a Secret
	tmpDir := t.TempDir()

	// Create a Secret (which may have SOPS fields that could fail validation)
	//nolint:gosec // G101: This is a test secret manifest, not a hardcoded credential
	secretYAML := `apiVersion: v1
kind: Secret
metadata:
  name: test-secret
  namespace: default
type: Opaque
data:
  key: dmFsdWU=
sops:
  # SOPS metadata that would fail validation without skip-secrets
  encrypted_regex: ^(data|stringData)$
`

	err := os.WriteFile(filepath.Join(tmpDir, "secret.yaml"), []byte(secretYAML), 0o600)
	if err != nil {
		t.Fatalf("failed to write secret: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{
		"--skip-secrets=true",
		tmpDir,
	})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation with skip-secrets to succeed, got error: %v", err)
	}
}

func TestValidateCmdWithVerboseFlag(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with a valid manifest
	tmpDir := t.TempDir()

	manifestPath := filepath.Join(tmpDir, "namespace.yaml")

	err := os.WriteFile(manifestPath, []byte(validNamespaceManifest), 0o600)
	if err != nil {
		t.Fatalf("failed to write test manifest: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{
		"--verbose",
		tmpDir,
	})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation to succeed, got error: %v", err)
	}

	// Note: We can't easily check for verbose output without capturing stdout/stderr
	// but we can verify the command ran successfully with the flag
}

//nolint:paralleltest // Cannot use t.Parallel() with t.Chdir() - they are incompatible
func TestValidateCmdWithDefaultPath(t *testing.T) {
	// Note: Cannot use t.Parallel() here because we use t.Chdir()

	// Create a temporary directory with a valid manifest and change to it
	tmpDir := t.TempDir()

	manifestPath := filepath.Join(tmpDir, "namespace.yaml")

	err := os.WriteFile(manifestPath, []byte(validNamespaceManifest), 0o600)
	if err != nil {
		t.Fatalf("failed to write test manifest: %v", err)
	}

	// Use t.Chdir to change directory (automatically reverts after test)
	t.Chdir(tmpDir)

	// Run validate without path argument (should use current directory)
	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation to succeed with default path, got error: %v", err)
	}
}

func TestValidateCmdWithEmptyDirectory(t *testing.T) {
	t.Parallel()

	// Create an empty temporary directory
	tmpDir := t.TempDir()

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{tmpDir})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	// Empty directory should succeed (no files to validate)
	err := cmd.Execute()
	if err != nil {
		t.Fatalf("expected validation of empty directory to succeed, got error: %v", err)
	}
}

func TestValidateCmdWithMixedValidAndInvalidFiles(t *testing.T) {
	t.Parallel()

	// Create a temporary directory with both valid and invalid manifests
	tmpDir := t.TempDir()

	// Valid manifest
	validManifest := `apiVersion: v1
kind: Namespace
metadata:
  name: test-namespace
`

	err := os.WriteFile(
		filepath.Join(tmpDir, "valid.yaml"),
		[]byte(validManifest),
		0o600,
	)
	if err != nil {
		t.Fatalf("failed to write valid manifest: %v", err)
	}

	// Invalid manifest
	invalidManifest := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
data: "invalid"
`

	err = os.WriteFile(
		filepath.Join(tmpDir, "invalid.yaml"),
		[]byte(invalidManifest),
		0o600,
	)
	if err != nil {
		t.Fatalf("failed to write invalid manifest: %v", err)
	}

	cmd := workload.NewValidateCmd()
	cmd.SetArgs([]string{tmpDir})

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	err = cmd.Execute()
	// Should fail because one file is invalid
	if err == nil {
		t.Fatal("expected validation to fail when directory contains invalid files")
	}
}

func setupValidManifestDir(t *testing.T) string {
	t.Helper()

	tmpDir := t.TempDir()
	manifestPath := filepath.Join(tmpDir, "namespace.yaml")

	err := os.WriteFile(manifestPath, []byte(validNamespaceManifest), 0o600)
	if err != nil {
		t.Fatalf("failed to write test manifest: %v", err)
	}

	return tmpDir
}

func TestValidateCmdFlagCombinations(t *testing.T) {
	t.Parallel()

	tmpDir := setupValidManifestDir(t)

	tests := []struct {
		name string
		args []string
	}{
		{
			name: "strict enabled",
			args: []string{"--strict=true", tmpDir},
		},
		{
			name: "strict disabled",
			args: []string{"--strict=false", tmpDir},
		},
		{
			name: "ignore-missing-schemas enabled",
			args: []string{"--ignore-missing-schemas=true", tmpDir},
		},
		{
			name: "ignore-missing-schemas disabled",
			args: []string{"--ignore-missing-schemas=false", tmpDir},
		},
		{
			name: "all flags",
			args: []string{
				"--skip-secrets=true",
				"--strict=true",
				"--ignore-missing-schemas=true",
				"--verbose",
				tmpDir,
			},
		},
	}

	for _, testCase := range tests {
		t.Run(testCase.name, func(t *testing.T) {
			t.Parallel()

			cmd := workload.NewValidateCmd()
			cmd.SetArgs(testCase.args)

			var output bytes.Buffer
			cmd.SetOut(&output)
			cmd.SetErr(&output)

			err := cmd.Execute()
			if err != nil {
				t.Fatalf(
					"expected validation to succeed with %s, got error: %v",
					testCase.name,
					err,
				)
			}
		})
	}
}
package workload_test

import (
	"bytes"
	"strings"
	"testing"

	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
)

func TestNewPushCmdHasValidateFlag(t *testing.T) {
	t.Parallel()

	cmd := workload.NewPushCmd(runtime.New(nil))

	// Check if --validate flag exists
	validateFlag := cmd.Flags().Lookup("validate")
	if validateFlag == nil {
		t.Fatal("expected --validate flag to exist")
	}

	// Check default value
	if validateFlag.DefValue != "false" {
		t.Fatalf(
			"expected --validate flag default value to be false, got %s",
			validateFlag.DefValue,
		)
	}

	// Check usage text
	expectedUsage := "Validate manifests before pushing"
	if validateFlag.Usage != expectedUsage {
		t.Fatalf(
			"expected --validate flag usage to be %q, got %q",
			expectedUsage,
			validateFlag.Usage,
		)
	}
}

func TestPushCmdShowsValidateFlagInHelp(t *testing.T) {
	t.Parallel()

	cmd := workload.NewPushCmd(runtime.New(nil))

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)
	cmd.SetArgs([]string{"--help"})

	err := cmd.Execute()
	if err != nil {
		t.Fatalf("expected no error executing push --help, got %v", err)
	}

	helpText := output.String()

	// Check that --validate flag is documented in help
	if !strings.Contains(helpText, "--validate") {
		t.Fatal("expected help text to include --validate flag")
	}

	if !strings.Contains(helpText, "Validate manifests before pushing") {
		t.Fatal("expected help text to include validate flag description")
	}
}

func TestPushCmdAcceptsValidateFlag(t *testing.T) {
	t.Parallel()

	testCases := []struct {
		name     string
		args     []string
		expected bool
	}{
		{
			name:     "validate flag not set",
			args:     []string{},
			expected: false,
		},
		{
			name:     "validate flag set to true",
			args:     []string{"--validate=true"},
			expected: true,
		},
		{
			name:     "validate flag set to false",
			args:     []string{"--validate=false"},
			expected: false,
		},
		{
			name:     "validate flag shorthand",
			args:     []string{"--validate"},
			expected: true,
		},
	}

	for _, testCase := range testCases {
		t.Run(testCase.name, func(t *testing.T) {
			t.Parallel()

			cmd := workload.NewPushCmd(runtime.New(nil))
			cmd.SetArgs(testCase.args)

			// Parse flags without executing the command
			err := cmd.ParseFlags(testCase.args)
			if err != nil {
				t.Fatalf("expected no error parsing flags, got %v", err)
			}

			validate, err := cmd.Flags().GetBool("validate")
			if err != nil {
				t.Fatalf("expected no error getting validate flag, got %v", err)
			}

			if validate != testCase.expected {
				t.Fatalf("expected validate flag to be %v, got %v", testCase.expected, validate)
			}
		})
	}
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewExposeCmd creates the workload expose command.
func NewExposeCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the expose command directly
	client := kubectl.NewClient(ioStreams)
	exposeCmd := client.CreateExposeCommand(kubeconfigPath)

	return exposeCmd
}
package workload

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/devantler-tech/ksail/v5/pkg/client/kubeconform"
	"github.com/devantler-tech/ksail/v5/pkg/client/kustomize"
	"github.com/devantler-tech/ksail/v5/pkg/utils/notify"
	"github.com/spf13/cobra"
)

const (
	kustomizationFileName = "kustomization.yaml"
)

// NewValidateCmd creates the workload validate command.
func NewValidateCmd() *cobra.Command {
	var (
		skipSecrets          bool
		strict               bool
		ignoreMissingSchemas bool
		verbose              bool
	)

	cmd := &cobra.Command{
		Use:   "validate [PATH]",
		Short: "Validate Kubernetes manifests and kustomizations",
		Long: `Validate Kubernetes manifest files and kustomizations using kubeconform.

This command validates individual YAML files and kustomizations in the specified path.
If no path is provided, it validates the current directory.

The validation process:
1. Validates individual YAML files
2. Validates kustomizations by building them with kustomize and validating the output

By default, Kubernetes Secrets are skipped to avoid validation failures due to SOPS fields.`,
		Args: cobra.MaximumNArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			return runValidateCmd(
				cmd.Context(),
				cmd,
				args,
				skipSecrets,
				strict,
				ignoreMissingSchemas,
				verbose,
			)
		},
	}

	// Add flags
	cmd.Flags().BoolVar(&skipSecrets, "skip-secrets", true, "Skip validation of Kubernetes Secrets")
	cmd.Flags().BoolVar(&strict, "strict", true, "Enable strict validation mode")
	cmd.Flags().BoolVar(
		&ignoreMissingSchemas,
		"ignore-missing-schemas",
		true,
		"Ignore resources with missing schemas",
	)
	cmd.Flags().BoolVar(&verbose, "verbose", false, "Enable verbose output")

	return cmd
}

func runValidateCmd(
	ctx context.Context,
	cmd *cobra.Command,
	args []string,
	skipSecrets bool,
	strict bool,
	ignoreMissingSchemas bool,
	verbose bool,
) error {
	// Default to current directory if no path provided
	path := "."
	if len(args) > 0 {
		path = args[0]
	}

	// Create kubeconform client
	kubeconformClient := kubeconform.NewClient()

	// Build validation options
	validationOpts := &kubeconform.ValidationOptions{
		Strict:               strict,
		IgnoreMissingSchemas: ignoreMissingSchemas,
		Verbose:              verbose,
	}
	if skipSecrets {
		validationOpts.SkipKinds = append(validationOpts.SkipKinds, "Secret")
	}

	// Validate the path
	err := validatePath(ctx, cmd, path, kubeconformClient, validationOpts)
	if err != nil {
		return err
	}

	notify.WriteMessage(notify.Message{
		Type:    notify.SuccessType,
		Content: "all validations passed",
		Writer:  cmd.OutOrStdout(),
	})

	return nil
}

// validatePath validates all manifests in the given path.
func validatePath(
	ctx context.Context,
	cmd *cobra.Command,
	path string,
	kubeconformClient *kubeconform.Client,
	opts *kubeconform.ValidationOptions,
) error {
	// Check if path exists
	info, err := os.Stat(path)
	if err != nil {
		return fmt.Errorf("access path %s: %w", path, err)
	}

	// If it's a file, validate it directly
	if !info.IsDir() {
		return validateFile(ctx, cmd, path, kubeconformClient, opts)
	}

	// If it's a directory, walk it to find YAML files and kustomizations
	return validateDirectory(ctx, cmd, path, kubeconformClient, opts)
}

// validateFile validates a single YAML file.
func validateFile(
	ctx context.Context,
	cmd *cobra.Command,
	filePath string,
	kubeconformClient *kubeconform.Client,
	opts *kubeconform.ValidationOptions,
) error {
	// Only validate YAML files
	if !isYAMLFile(filePath) {
		return nil
	}

	notify.WriteMessage(notify.Message{
		Type:    notify.ActivityType,
		Content: "validating %s",
		Args:    []any{filePath},
		Writer:  cmd.OutOrStdout(),
	})

	err := kubeconformClient.ValidateFile(ctx, filePath, opts)
	if err != nil {
		return fmt.Errorf("validate file %s: %w", filePath, err)
	}

	return nil
}

// validateDirectory validates all YAML files and kustomizations in a directory.
// Validation is performed in parallel with live progress display for better UX.
//
//nolint:funlen // Orchestrates parallel validation with progress display
func validateDirectory(
	ctx context.Context,
	cmd *cobra.Command,
	dirPath string,
	kubeconformClient *kubeconform.Client,
	opts *kubeconform.ValidationOptions,
) error {
	// Find all kustomizations
	kustomizations, err := findKustomizations(dirPath)
	if err != nil {
		return fmt.Errorf("find kustomizations: %w", err)
	}

	// Find all YAML files
	yamlFiles, err := findYAMLFiles(dirPath)
	if err != nil {
		return fmt.Errorf("find YAML files: %w", err)
	}

	// Validate kustomizations in parallel with progress display
	if len(kustomizations) > 0 {
		kustomizeClient := kustomize.NewClient()

		tasks := make([]notify.ProgressTask, len(kustomizations))
		for i, kustDir := range kustomizations {
			tasks[i] = notify.ProgressTask{
				Name: filepath.Base(kustDir),
				Fn: func(taskCtx context.Context) error {
					return validateKustomizationSilent(
						taskCtx,
						kustDir,
						kubeconformClient,
						kustomizeClient,
						opts,
					)
				},
			}
		}

		progressGroup := notify.NewProgressGroup(
			"Validating kustomizations",
			"âœ…",
			cmd.OutOrStdout(),
			notify.WithLabels(notify.ValidatingLabels()),
		)

		pgErr := progressGroup.Run(ctx, tasks...)
		if pgErr != nil {
			return fmt.Errorf("kustomization validation failed: %w", pgErr)
		}
	}

	// Validate individual YAML files in parallel with progress display
	if len(yamlFiles) > 0 {
		tasks := make([]notify.ProgressTask, len(yamlFiles))
		for i, file := range yamlFiles {
			tasks[i] = notify.ProgressTask{
				Name: filepath.Base(file),
				Fn: func(taskCtx context.Context) error {
					return validateFileSilent(taskCtx, file, kubeconformClient, opts)
				},
			}
		}

		progressGroup := notify.NewProgressGroup(
			"Validating YAML files",
			"ðŸ“„",
			cmd.OutOrStdout(),
			notify.WithLabels(notify.ValidatingLabels()),
		)

		pgErr := progressGroup.Run(ctx, tasks...)
		if pgErr != nil {
			return fmt.Errorf("YAML validation failed: %w", pgErr)
		}
	}

	return nil
}

// validateKustomizationSilent validates a kustomization without output (for parallel execution).
func validateKustomizationSilent(
	ctx context.Context,
	kustDir string,
	kubeconformClient *kubeconform.Client,
	kustomizeClient *kustomize.Client,
	opts *kubeconform.ValidationOptions,
) error {
	// Build the kustomization
	output, err := kustomizeClient.Build(ctx, kustDir)
	if err != nil {
		return fmt.Errorf("build kustomization %s: %w", kustDir, err)
	}

	// Validate the output
	err = kubeconformClient.ValidateManifests(ctx, output, opts)
	if err != nil {
		return fmt.Errorf("validate kustomization %s: %w", kustDir, err)
	}

	return nil
}

// validateFileSilent validates a single YAML file without output (for parallel execution).
func validateFileSilent(
	ctx context.Context,
	filePath string,
	kubeconformClient *kubeconform.Client,
	opts *kubeconform.ValidationOptions,
) error {
	// Only validate YAML files
	if !isYAMLFile(filePath) {
		return nil
	}

	err := kubeconformClient.ValidateFile(ctx, filePath, opts)
	if err != nil {
		return fmt.Errorf("validate file %s: %w", filePath, err)
	}

	return nil
}

// findKustomizations finds all directories containing kustomization.yaml files.
func findKustomizations(rootPath string) ([]string, error) {
	var kustomizations []string

	err := filepath.Walk(rootPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if !info.IsDir() && info.Name() == kustomizationFileName {
			kustomizations = append(kustomizations, filepath.Dir(path))
		}

		return nil
	})
	if err != nil {
		return nil, fmt.Errorf("walk directory %s: %w", rootPath, err)
	}

	return kustomizations, nil
}

// findYAMLFiles finds all YAML files in a directory, excluding kustomization.yaml files.
func findYAMLFiles(rootPath string) ([]string, error) {
	var yamlFiles []string

	err := filepath.Walk(rootPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		// Skip kustomization.yaml files as they are validated separately via kustomize build
		if !info.IsDir() && isYAMLFile(path) && filepath.Base(path) != kustomizationFileName {
			yamlFiles = append(yamlFiles, path)
		}

		return nil
	})
	if err != nil {
		return nil, fmt.Errorf("walk directory %s: %w", rootPath, err)
	}

	return yamlFiles, nil
}

// isYAMLFile checks if a file has a YAML extension.
func isYAMLFile(filePath string) bool {
	ext := strings.ToLower(filepath.Ext(filePath))

	return ext == ".yaml" || ext == ".yml"
}
// Package workload provides the workload command namespace.
//
// This package groups all workload-related commands for managing Kubernetes
// resources, including reconcile, push, apply, create, delete, describe, edit, exec,
// explain, expose, get, gen, install, logs, rollout, scale, validate, and wait operations.
package workload
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewDescribeCmd creates the workload describe command.
func NewDescribeCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the describe command directly
	client := kubectl.NewClient(ioStreams)
	describeCmd := client.CreateDescribeCommand(kubeconfigPath)

	return describeCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewEditCmd creates the workload edit command.
func NewEditCmd() *cobra.Command {
	var editorFlag string

	cmd := &cobra.Command{
		Use:   "edit",
		Short: "Edit a resource",
		Long: `Edit a Kubernetes resource from the default editor.

The editor is determined by (in order of precedence):
  1. --editor flag
  2. spec.editor from ksail.yaml config
  3. KUBE_EDITOR, EDITOR, or VISUAL environment variables
  4. Fallback to vim, nano, or vi

Example:
  ksail workload edit deployment/my-deployment
  ksail workload edit --editor "code --wait" deployment/my-deployment`,
		SilenceUsage: true,
		RunE: func(cmd *cobra.Command, args []string) error {
			// Set up editor environment variables before edit
			cleanup := helpers.SetupEditorEnv(editorFlag, "workload")
			defer cleanup()

			// Try to load config silently to get kubeconfig path
			kubeconfigPath := helpers.GetKubeconfigPathSilently()

			// Create IO streams for kubectl
			ioStreams := genericiooptions.IOStreams{
				In:     os.Stdin,
				Out:    os.Stdout,
				ErrOut: os.Stderr,
			}

			// Create kubectl client and get the edit command directly
			client := kubectl.NewClient(ioStreams)
			editCmd := client.CreateEditCommand(kubeconfigPath)

			// Transfer the context from parent command
			editCmd.SetContext(cmd.Context())

			// Set the args that were passed through
			editCmd.SetArgs(args)

			// Execute kubectl edit command
			return editCmd.Execute()
		},
	}

	cmd.Flags().StringVar(
		&editorFlag,
		"editor",
		"",
		"editor command to use (e.g., 'code --wait', 'vim', 'nano')",
	)

	return cmd
}
package workload_test

// cspell:words cmdtestutils

import (
	"bytes"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd"
	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/devantler-tech/ksail/v5/pkg/utils/timer"
	"github.com/gkampitakis/go-snaps/snaps"
	"github.com/samber/do/v2"
	"github.com/stretchr/testify/require"
)

func TestMain(m *testing.M) {
	exitCode := m.Run()

	_, err := snaps.Clean(m, snaps.CleanOpts{Sort: true})
	if err != nil {
		_, _ = os.Stderr.WriteString("failed to clean snapshots: " + err.Error() + "\n")

		os.Exit(1)
	}

	os.Exit(exitCode)
}

func writeValidKsailConfig(t *testing.T, dir string) {
	t.Helper()

	workloadDir := filepath.Join(dir, "k8s")
	require.NoError(t, os.MkdirAll(workloadDir, 0o750))

	ksailConfigContent := "apiVersion: ksail.dev/v1alpha1\n" +
		"kind: Cluster\n" +
		"spec:\n" +
		"  distribution: Kind\n" +
		"  distributionConfig: kind.yaml\n" +
		"  sourceDirectory: k8s\n"

	configPath := filepath.Join(dir, "ksail.yaml")
	require.NoError(t, os.WriteFile(configPath, []byte(ksailConfigContent), 0o600))

	kindConfigContent := "kind: Cluster\n" +
		"apiVersion: kind.x-k8s.io/v1alpha4\n" +
		"name: kind\n"

	kindConfigPath := filepath.Join(dir, "kind.yaml")
	require.NoError(t, os.WriteFile(kindConfigPath, []byte(kindConfigContent), 0o600))
}

func TestWorkloadHelpSnapshots(t *testing.T) {
	t.Parallel()

	testCases := []struct {
		name string
		args []string
	}{
		{name: "namespace", args: []string{"workload", "--help"}},
		{name: "reconcile", args: []string{"workload", "reconcile", "--help"}},
		{name: "push", args: []string{"workload", "push", "--help"}},
		{name: "apply", args: []string{"workload", "apply", "--help"}},
		{name: "create", args: []string{"workload", "create", "--help"}},
		{name: "create_source", args: []string{"workload", "create", "source", "--help"}},
		{
			name: "create_kustomization",
			args: []string{"workload", "create", "kustomization", "--help"},
		},
		// NOTE: create_helmrelease snapshot test temporarily disabled due to snapshot system issue
		// {name: "create_helmrelease", args: []string{"workload", "create", "helmrelease", "--help"}},
		{name: "delete", args: []string{"workload", "delete", "--help"}},
		{name: "describe", args: []string{"workload", "describe", "--help"}},
		{name: "edit", args: []string{"workload", "edit", "--help"}},
		{name: "exec", args: []string{"workload", "exec", "--help"}},
		{name: "explain", args: []string{"workload", "explain", "--help"}},
		{name: "expose", args: []string{"workload", "expose", "--help"}},
		{name: "get", args: []string{"workload", "get", "--help"}},
		{name: "install", args: []string{"workload", "install", "--help"}},
		{name: "logs", args: []string{"workload", "logs", "--help"}},
		{name: "rollout", args: []string{"workload", "rollout", "--help"}},
		{name: "scale", args: []string{"workload", "scale", "--help"}},
		{name: "wait", args: []string{"workload", "wait", "--help"}},
	}

	for _, testCase := range testCases {
		t.Run(testCase.name, func(t *testing.T) {
			t.Parallel()

			var out bytes.Buffer

			root := cmd.NewRootCmd("test", "test", "test")
			root.SetOut(&out)
			root.SetErr(&out)
			root.SetArgs(testCase.args)

			err := root.Execute()
			require.NoErrorf(
				t,
				err,
				"expected no error executing %s help",
				strings.Join(testCase.args, " "),
			)

			snaps.MatchSnapshot(t, out.String())
		})
	}
}

//nolint:paralleltest // Uses t.Chdir which is incompatible with parallel tests.
func TestWorkloadCommandsLoadConfigOnly(t *testing.T) {
	// Note: "apply" and "install" are excluded as they are full implementations with kubectl/helm wrappers
	commands := []string{"reconcile", "push"}

	for _, commandName := range commands {
		t.Run(commandName, func(t *testing.T) {
			var out bytes.Buffer

			tempDir := t.TempDir()
			writeValidKsailConfig(t, tempDir)

			t.Chdir(tempDir)

			root := cmd.NewRootCmd("test", "test", "test")
			root.SetOut(&out)
			root.SetErr(&out)
			root.SetArgs([]string{"workload", commandName})

			err := root.Execute()
			require.ErrorContains(
				t,
				err,
				"GitOps engine must be enabled",
				"expected workload %s handler to require GitOps engine (push also requires local registry)",
				commandName,
			)

			actual := out.String()
			require.Contains(t, actual, "config loaded")
			require.NotContains(t, actual, "coming soon")
			require.NotContains(t, actual, "â„¹")
		})
	}
}

func TestNewWorkloadCmdRunETriggersHelp(t *testing.T) {
	t.Parallel()

	runtimeContainer := runtime.New(func(injector do.Injector) error {
		do.Provide(injector, func(do.Injector) (timer.Timer, error) {
			return timer.New(), nil
		})

		return nil
	})

	var out bytes.Buffer

	command := workload.NewWorkloadCmd(runtimeContainer)
	command.SetOut(&out)
	command.SetErr(&out)

	err := command.Execute()
	require.NoError(t, err)

	snaps.MatchSnapshot(t, out.String())
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewExecCmd creates the workload exec command.
func NewExecCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the exec command directly
	client := kubectl.NewClient(ioStreams)
	execCmd := client.CreateExecCommand(kubeconfigPath)

	return execCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/flux"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewCreateCmd creates the workload create command.
// The runtime parameter is kept for consistency with other workload command constructors,
// though it's currently unused as this command wraps kubectl and flux directly.
func NewCreateCmd(_ *runtime.Runtime) *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl and flux
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the create command directly
	kubectlClient := kubectl.NewClient(ioStreams)
	createCmd := kubectlClient.CreateCreateCommand(kubeconfigPath)

	// Create flux client and add flux create sub-commands
	fluxClient := flux.NewClient(ioStreams, kubeconfigPath)
	fluxCreateCmd := fluxClient.CreateCreateCommand(kubeconfigPath)

	// Add all flux create sub-commands to the main create command
	for _, subCmd := range fluxCreateCmd.Commands() {
		createCmd.AddCommand(subCmd)
	}

	return createCmd
}
package workload

import (
	"context"
	"errors"
	"fmt"
	"io"
	"strings"
	"time"

	v1alpha1 "github.com/devantler-tech/ksail/v5/pkg/apis/cluster/v1alpha1"
	"github.com/devantler-tech/ksail/v5/pkg/client/argocd"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	iopath "github.com/devantler-tech/ksail/v5/pkg/io"
	"github.com/devantler-tech/ksail/v5/pkg/k8s"
	"github.com/devantler-tech/ksail/v5/pkg/svc/provisioner/registry"
	"github.com/devantler-tech/ksail/v5/pkg/utils/notify"
	"github.com/devantler-tech/ksail/v5/pkg/utils/timer"
	"github.com/spf13/cobra"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
	"k8s.io/apimachinery/pkg/runtime/schema"
	"k8s.io/client-go/dynamic"
)

//nolint:staticcheck // "GitOps" is a proper noun and must be capitalized
var errGitOpsEngineRequired = errors.New(
	"A GitOps engine must be enabled to reconcile workloads; " +
		"enable it with '--gitops-engine Flux|ArgoCD' during cluster init or " +
		"set 'spec.gitOpsEngine: Flux|ArgoCD' in ksail.yaml",
)

var errLocalRegistryRequired = errors.New(
	"local registry and a GitOps engine must be enabled to push workloads; " +
		"enable it with '--local-registry Enabled' and '--gitops-engine Flux|ArgoCD' " +
		"during cluster init or set 'spec.localRegistry: Enabled' and " +
		"'spec.gitOpsEngine: Flux|ArgoCD' in ksail.yaml",
)

var (
	errFluxReconcileTimeout   = errors.New("timeout waiting for flux kustomization reconciliation")
	errArgoCDReconcileTimeout = errors.New("timeout waiting for argocd application sync")
)

const (
	fluxNamespace             = "flux-system"
	fluxRootKustomizationName = "flux-system"
	argoCDNamespace           = "argocd"
	argoCDRootApplicationName = "ksail"
	defaultReconcileTimeout   = 5 * time.Minute
	reconcilePollInterval     = 2 * time.Second
)

// reconcileFluxKustomization triggers and waits for Flux kustomization reconciliation.
func reconcileFluxKustomization(
	ctx context.Context,
	clusterCfg *v1alpha1.Cluster,
	timeout time.Duration,
	outputTimer timer.Timer,
	writer io.Writer,
) error {
	kubeconfigPath, err := getKubeconfigPath(clusterCfg)
	if err != nil {
		return err
	}

	writeActivityNotification(
		"triggering flux kustomization reconciliation",
		outputTimer,
		writer,
	)

	kustomizationClient, err := getFluxKustomizationClient(kubeconfigPath)
	if err != nil {
		return err
	}

	err = triggerFluxReconciliation(ctx, kustomizationClient)
	if err != nil {
		return err
	}

	writeActivityNotification(
		"waiting for flux kustomization to reconcile",
		outputTimer,
		writer,
	)

	return waitForFluxReconciliation(ctx, kustomizationClient, timeout)
}

// getKubeconfigPath returns the kubeconfig path from config or default.
func getKubeconfigPath(clusterCfg *v1alpha1.Cluster) (string, error) {
	kubeconfigPath := strings.TrimSpace(clusterCfg.Spec.Cluster.Connection.Kubeconfig)
	if kubeconfigPath == "" {
		kubeconfigPath = v1alpha1.DefaultKubeconfigPath
	}

	expanded, err := iopath.ExpandHomePath(kubeconfigPath)
	if err != nil {
		return "", fmt.Errorf("expand kubeconfig path: %w", err)
	}

	return expanded, nil
}

// getFluxKustomizationClient creates a dynamic client for Flux kustomizations.
func getFluxKustomizationClient(
	kubeconfigPath string,
) (dynamic.ResourceInterface, error) {
	kustomizationGVR := schema.GroupVersionResource{
		Group:    "kustomize.toolkit.fluxcd.io",
		Version:  "v1",
		Resource: "kustomizations",
	}

	return getDynamicResourceClient(kubeconfigPath, kustomizationGVR, fluxNamespace)
}

// triggerFluxReconciliation annotates the kustomization to trigger reconciliation.
func triggerFluxReconciliation(
	ctx context.Context,
	kustomizationClient dynamic.ResourceInterface,
) error {
	kustomization, err := kustomizationClient.Get(
		ctx,
		fluxRootKustomizationName,
		metav1.GetOptions{},
	)
	if err != nil {
		return fmt.Errorf("get flux kustomization: %w", err)
	}

	annotations := kustomization.GetAnnotations()
	if annotations == nil {
		annotations = make(map[string]string)
	}

	annotations["reconcile.fluxcd.io/requestedAt"] = time.Now().Format(time.RFC3339Nano)
	kustomization.SetAnnotations(annotations)

	_, err = kustomizationClient.Update(ctx, kustomization, metav1.UpdateOptions{})
	if err != nil {
		return fmt.Errorf("trigger flux reconciliation: %w", err)
	}

	return nil
}

// waitForFluxReconciliation waits for the kustomization to become ready.
func waitForFluxReconciliation(
	ctx context.Context,
	kustomizationClient dynamic.ResourceInterface,
	timeout time.Duration,
) error {
	return waitForResourceCondition(
		ctx,
		kustomizationClient,
		fluxRootKustomizationName,
		timeout,
		isFluxKustomizationReady,
		errFluxReconcileTimeout,
		"get flux kustomization status",
	)
}

// isFluxKustomizationReady checks if the kustomization has Ready=True condition.
func isFluxKustomizationReady(kustomization *unstructured.Unstructured) bool {
	conditions, found, err := unstructured.NestedSlice(kustomization.Object, "status", "conditions")
	if err != nil || !found {
		return false
	}

	for _, condition := range conditions {
		condMap, ok := condition.(map[string]any)
		if !ok {
			continue
		}

		condType, _, _ := unstructured.NestedString(condMap, "type")
		condStatus, _, _ := unstructured.NestedString(condMap, "status")

		if condType == "Ready" && condStatus == "True" {
			return true
		}
	}

	return false
}

// reconcileArgoCDApplication refreshes and waits for the ArgoCD application to sync.
func reconcileArgoCDApplication(
	ctx context.Context,
	clusterCfg *v1alpha1.Cluster,
	artifactVersion string,
	timeout time.Duration,
	outputTimer timer.Timer,
	writer io.Writer,
) error {
	kubeconfigPath, err := getKubeconfigPath(clusterCfg)
	if err != nil {
		return err
	}

	writeActivityNotification(
		"triggering argocd application refresh",
		outputTimer,
		writer,
	)

	err = triggerArgoCDRefresh(ctx, kubeconfigPath, artifactVersion)
	if err != nil {
		return err
	}

	writeActivityNotification(
		"waiting for argocd application to sync",
		outputTimer,
		writer,
	)

	applicationClient, err := getArgoCDApplicationClient(kubeconfigPath)
	if err != nil {
		return err
	}

	return waitForArgoCDSync(ctx, applicationClient, timeout)
}

// triggerArgoCDRefresh triggers a hard refresh of the ArgoCD application.
func triggerArgoCDRefresh(
	ctx context.Context,
	kubeconfigPath string,
	artifactVersion string,
) error {
	argocdMgr, err := argocd.NewManagerFromKubeconfig(kubeconfigPath)
	if err != nil {
		return fmt.Errorf("create argocd manager: %w", err)
	}

	err = argocdMgr.UpdateTargetRevision(ctx, argocd.UpdateTargetRevisionOptions{
		TargetRevision: artifactVersion,
		HardRefresh:    true,
	})
	if err != nil {
		return fmt.Errorf("refresh argocd application: %w", err)
	}

	return nil
}

// getArgoCDApplicationClient creates a dynamic client for ArgoCD applications.
func getArgoCDApplicationClient(kubeconfigPath string) (dynamic.ResourceInterface, error) {
	applicationGVR := schema.GroupVersionResource{
		Group:    "argoproj.io",
		Version:  "v1alpha1",
		Resource: "applications",
	}

	return getDynamicResourceClient(kubeconfigPath, applicationGVR, argoCDNamespace)
}

// getDynamicResourceClient creates a dynamic Kubernetes client for a specific resource.
func getDynamicResourceClient(
	kubeconfigPath string,
	gvr schema.GroupVersionResource,
	namespace string,
) (dynamic.ResourceInterface, error) {
	restConfig, err := k8s.BuildRESTConfig(kubeconfigPath, "")
	if err != nil {
		return nil, fmt.Errorf("build rest config: %w", err)
	}

	dynamicClient, err := dynamic.NewForConfig(restConfig)
	if err != nil {
		return nil, fmt.Errorf("create dynamic client: %w", err)
	}

	return dynamicClient.Resource(gvr).Namespace(namespace), nil
}

// waitForArgoCDSync waits for the application to sync and become healthy.
func waitForArgoCDSync(
	ctx context.Context,
	applicationClient dynamic.ResourceInterface,
	timeout time.Duration,
) error {
	return waitForResourceCondition(
		ctx,
		applicationClient,
		argoCDRootApplicationName,
		timeout,
		isArgoCDApplicationSynced,
		errArgoCDReconcileTimeout,
		"get argocd application status",
	)
}

// waitForResourceCondition is a generic function to wait for a resource to meet a condition.
func waitForResourceCondition(
	ctx context.Context,
	client dynamic.ResourceInterface,
	resourceName string,
	timeout time.Duration,
	checkCondition func(*unstructured.Unstructured) bool,
	timeoutErr error,
	errorMsg string,
) error {
	timeoutCtx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	ticker := time.NewTicker(reconcilePollInterval)
	defer ticker.Stop()

	for {
		select {
		case <-timeoutCtx.Done():
			return timeoutErr
		case <-ticker.C:
			resource, err := client.Get(timeoutCtx, resourceName, metav1.GetOptions{})
			if err != nil {
				return fmt.Errorf("%s: %w", errorMsg, err)
			}

			if checkCondition(resource) {
				return nil
			}
		}
	}
}

// isArgoCDApplicationSynced checks if the application is synced and healthy.
func isArgoCDApplicationSynced(app *unstructured.Unstructured) bool {
	syncStatus, found, err := unstructured.NestedString(app.Object, "status", "sync", "status")
	if err != nil || !found {
		return false
	}

	healthStatus, found, err := unstructured.NestedString(app.Object, "status", "health", "status")
	if err != nil || !found {
		return false
	}

	return syncStatus == "Synced" && healthStatus == "Healthy"
}

// NewReconcileCmd creates the workload reconcile command.
func NewReconcileCmd(_ *runtime.Runtime) *cobra.Command {
	cmd := &cobra.Command{
		Use:          "reconcile",
		Short:        "Trigger reconciliation for GitOps workloads",
		Long:         "Trigger reconciliation/sync for the root Flux kustomization or root ArgoCD application.",
		SilenceUsage: true,
	}

	cmd.Flags().Duration(
		"timeout",
		0,
		"timeout for waiting for reconciliation to complete (overrides config timeout)",
	)

	cmd.RunE = func(cmd *cobra.Command, _ []string) error {
		return runReconcile(cmd)
	}

	return cmd
}

// runReconcile executes the reconcile command logic.
func runReconcile(cmd *cobra.Command) error {
	ctx, err := initCommandContext(cmd)
	if err != nil {
		return err
	}

	clusterCfg := ctx.ClusterCfg
	outputTimer := ctx.OutputTimer
	tmr := ctx.Timer

	if clusterCfg.Spec.Cluster.GitOpsEngine == v1alpha1.GitOpsEngineNone {
		return errGitOpsEngineRequired
	}

	timeout, err := getReconcileTimeout(cmd, clusterCfg)
	if err != nil {
		return err
	}

	cmd.Println()
	notify.WriteMessage(notify.Message{
		Type:    notify.TitleType,
		Emoji:   "ðŸ”„",
		Content: "Trigger Reconciliation...",
		Writer:  cmd.OutOrStdout(),
	})

	tmr.NewStage()

	err = executeReconciliation(cmd, clusterCfg, timeout, outputTimer)
	if err != nil {
		return err
	}

	notify.WriteMessage(notify.Message{
		Type:    notify.SuccessType,
		Content: "reconciliation completed",
		Timer:   outputTimer,
		Writer:  cmd.OutOrStdout(),
	})

	return nil
}

// getReconcileTimeout determines the timeout from flag, config, or default.
func getReconcileTimeout(cmd *cobra.Command, clusterCfg *v1alpha1.Cluster) (time.Duration, error) {
	timeout, err := cmd.Flags().GetDuration("timeout")
	if err != nil {
		return 0, fmt.Errorf("get timeout flag: %w", err)
	}

	if timeout == 0 {
		if clusterCfg.Spec.Cluster.Connection.Timeout.Duration > 0 {
			timeout = clusterCfg.Spec.Cluster.Connection.Timeout.Duration
		} else {
			timeout = defaultReconcileTimeout
		}
	}

	return timeout, nil
}

// executeReconciliation runs the appropriate reconciliation based on GitOps engine.
func executeReconciliation(
	cmd *cobra.Command,
	clusterCfg *v1alpha1.Cluster,
	timeout time.Duration,
	outputTimer timer.Timer,
) error {
	artifactVersion := registry.DefaultLocalArtifactTag

	switch clusterCfg.Spec.Cluster.GitOpsEngine {
	case v1alpha1.GitOpsEngineArgoCD:
		return reconcileArgoCDApplication(
			cmd.Context(),
			clusterCfg,
			artifactVersion,
			timeout,
			outputTimer,
			cmd.OutOrStdout(),
		)
	case v1alpha1.GitOpsEngineFlux:
		return reconcileFluxKustomization(
			cmd.Context(),
			clusterCfg,
			timeout,
			outputTimer,
			cmd.OutOrStdout(),
		)
	case v1alpha1.GitOpsEngineNone:
		return errGitOpsEngineRequired
	default:
		return errGitOpsEngineRequired
	}
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewWaitCmd creates the workload wait command.
func NewWaitCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the wait command directly
	client := kubectl.NewClient(ioStreams)
	waitCmd := client.CreateWaitCommand(kubeconfigPath)

	return waitCmd
}
package workload

import (
	"fmt"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/helm"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

const requiredInstallArgs = 2

// NewInstallCmd creates the workload install command.
func NewInstallCmd(_ *runtime.Runtime) *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	cmd := &cobra.Command{
		Use:   "install [NAME] [CHART]",
		Short: "Install Helm charts",
		Long: "Install Helm charts to provision workloads through KSail. " +
			"This command provides native Helm chart installation capabilities.",
		Args: cobra.ExactArgs(requiredInstallArgs),
		RunE: func(cmd *cobra.Command, args []string) error {
			releaseName := args[0]
			chartName := args[1]

			// Create helm client
			client, err := helm.NewClient(kubeconfigPath, "")
			if err != nil {
				return fmt.Errorf("create helm client: %w", err)
			}

			// Get namespace from flag or use default
			namespace, _ := cmd.Flags().GetString("namespace")
			if namespace == "" {
				namespace = "default"
			}

			// Create chart spec
			spec := &helm.ChartSpec{
				ReleaseName: releaseName,
				ChartName:   chartName,
				Namespace:   namespace,
				Timeout:     helm.DefaultTimeout,
			}

			// Get other flags
			if createNamespace, _ := cmd.Flags().GetBool("create-namespace"); createNamespace {
				spec.CreateNamespace = true
			}

			if wait, _ := cmd.Flags().GetBool("wait"); wait {
				spec.Wait = true
			}

			if atomic, _ := cmd.Flags().GetBool("atomic"); atomic {
				spec.Atomic = true
			}

			// Install chart
			_, err = client.InstallChart(cmd.Context(), spec)
			if err != nil {
				return fmt.Errorf("install chart %q: %w", chartName, err)
			}

			return nil
		},
	}

	// Add basic Helm install flags
	flags := cmd.Flags()
	flags.StringP("namespace", "n", "default", "namespace scope for the request")
	flags.Bool("create-namespace", false, "create the release namespace if not present")
	flags.Bool("wait", false, "wait until resources are ready")
	flags.Bool("atomic", false, "if set, the installation deletes on failure")

	return cmd
}
package workload_test

import (
	"bytes"
	"context"
	"fmt"
	"strings"
	"testing"
	"time"

	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
)

func TestNewInstallCmdRequiresMinimumArgs(t *testing.T) {
	t.Parallel()

	cmd := workload.NewInstallCmd(runtime.NewRuntime())
	cmd.SetOut(&bytes.Buffer{})
	cmd.SetErr(&bytes.Buffer{})

	err := cmd.Execute()
	if err == nil {
		t.Fatalf("expected argument validation error")
	}
}

func TestInstallCommandUsesDefaultNamespace(t *testing.T) {
	t.Parallel()

	err := runInstallCmd(t, "release", "./missing-chart")
	if err == nil {
		t.Fatalf("expected installation error due to missing chart")
	}

	if !strings.Contains(err.Error(), "install chart \"./missing-chart\"") {
		t.Fatalf("unexpected error: %v", err)
	}
}

func TestInstallCommandHonorsFlags(t *testing.T) {
	t.Parallel()

	err := runInstallCmd(
		t,
		"release",
		"./still-missing",
		"--namespace",
		"team",
		"--create-namespace",
		"--wait",
		"--atomic",
	)
	if err == nil {
		t.Fatalf("expected installation error due to missing chart")
	}

	if !strings.Contains(err.Error(), "install chart \"./still-missing\"") {
		t.Fatalf("unexpected error: %v", err)
	}
}

func runInstallCmd(t *testing.T, args ...string) error {
	t.Helper()

	cmd := workload.NewInstallCmd(runtime.NewRuntime())

	var output bytes.Buffer
	cmd.SetOut(&output)
	cmd.SetErr(&output)

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)
	t.Cleanup(cancel)
	cmd.SetContext(ctx)
	cmd.SetArgs(args)

	err := cmd.Execute()
	if err != nil {
		return fmt.Errorf("execute install command: %w", err)
	}

	return nil
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewDeleteCmd creates the workload delete command.
func NewDeleteCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the delete command directly
	client := kubectl.NewClient(ioStreams)
	deleteCmd := client.CreateDeleteCommand(kubeconfigPath)

	return deleteCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewRolloutCmd creates the workload rollout command.
func NewRolloutCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the rollout command directly
	client := kubectl.NewClient(ioStreams)
	rolloutCmd := client.CreateRolloutCommand(kubeconfigPath)

	return rolloutCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewApplyCmd creates the workload apply command.
func NewApplyCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the apply command directly
	client := kubectl.NewClient(ioStreams)
	applyCmd := client.CreateApplyCommand(kubeconfigPath)

	return applyCmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewGetCmd creates the workload get command.
func NewGetCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the get command directly
	client := kubectl.NewClient(ioStreams)
	getCmd := client.CreateGetCommand(kubeconfigPath)

	return getCmd
}
package workload

import (
	"fmt"
	"io"

	v1alpha1 "github.com/devantler-tech/ksail/v5/pkg/apis/cluster/v1alpha1"
	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	ksailconfigmanager "github.com/devantler-tech/ksail/v5/pkg/io/config-manager/ksail"
	"github.com/devantler-tech/ksail/v5/pkg/utils/notify"
	"github.com/devantler-tech/ksail/v5/pkg/utils/timer"
	"github.com/spf13/cobra"
)

// commandContext holds common command execution context.
type commandContext struct {
	Timer       timer.Timer
	OutputTimer timer.Timer
	ClusterCfg  *v1alpha1.Cluster
}

// initCommandContext initializes common command context (timer, config manager, config loading).
func initCommandContext(cmd *cobra.Command) (*commandContext, error) {
	tmr := timer.New()
	tmr.Start()

	fieldSelectors := ksailconfigmanager.DefaultClusterFieldSelectors()
	cfgManager := ksailconfigmanager.NewCommandConfigManager(cmd, fieldSelectors)
	outputTimer := helpers.MaybeTimer(cmd, tmr)

	clusterCfg, err := cfgManager.LoadConfig(outputTimer)
	if err != nil {
		return nil, fmt.Errorf("load config: %w", err)
	}

	return &commandContext{
		Timer:       tmr,
		OutputTimer: outputTimer,
		ClusterCfg:  clusterCfg,
	}, nil
}

// writeActivityNotification writes an activity notification message.
func writeActivityNotification(
	content string,
	outputTimer timer.Timer,
	writer io.Writer,
) {
	notify.WriteMessage(notify.Message{
		Type:    notify.ActivityType,
		Content: content,
		Timer:   outputTimer,
		Writer:  writer,
	})
}
package workload

import (
	"github.com/devantler-tech/ksail/v5/pkg/cli/cmd/workload/gen"
	runtime "github.com/devantler-tech/ksail/v5/pkg/di"
	"github.com/spf13/cobra"
)

// NewWorkloadCmd creates and returns the workload command group namespace.
func NewWorkloadCmd(runtimeContainer *runtime.Runtime) *cobra.Command {
	cmd := &cobra.Command{
		Use:   "workload",
		Short: "Manage workload operations",
		Long: "Group workload commands under a single namespace to reconcile, apply, create, delete, describe, edit, exec, " +
			"explain, expose, get, gen, install, logs, push, rollout, scale, validate, or wait for workloads.",
		Args: cobra.NoArgs,
		RunE: func(cmd *cobra.Command, _ []string) error {
			return cmd.Help()
		},
		SilenceUsage: true,
	}

	cmd.AddCommand(NewReconcileCmd(runtimeContainer))
	cmd.AddCommand(NewPushCmd(runtimeContainer))
	cmd.AddCommand(NewApplyCmd())
	cmd.AddCommand(NewCreateCmd(runtimeContainer))
	cmd.AddCommand(NewDeleteCmd())
	cmd.AddCommand(NewDescribeCmd())
	cmd.AddCommand(NewEditCmd())
	cmd.AddCommand(NewExecCmd())
	cmd.AddCommand(NewExplainCmd())
	cmd.AddCommand(NewExposeCmd())
	cmd.AddCommand(NewGetCmd())
	cmd.AddCommand(gen.NewGenCmd(runtimeContainer))
	cmd.AddCommand(NewInstallCmd(runtimeContainer))
	cmd.AddCommand(NewLogsCmd())
	cmd.AddCommand(NewRolloutCmd())
	cmd.AddCommand(NewScaleCmd())
	cmd.AddCommand(NewValidateCmd())
	cmd.AddCommand(NewWaitCmd())

	return cmd
}
package workload

import (
	"os"

	"github.com/devantler-tech/ksail/v5/pkg/cli/helpers"
	"github.com/devantler-tech/ksail/v5/pkg/client/kubectl"
	"github.com/spf13/cobra"
	"k8s.io/cli-runtime/pkg/genericiooptions"
)

// NewExplainCmd creates the workload explain command.
func NewExplainCmd() *cobra.Command {
	// Try to load config silently to get kubeconfig path
	kubeconfigPath := helpers.GetKubeconfigPathSilently()

	// Create IO streams for kubectl
	ioStreams := genericiooptions.IOStreams{
		In:     os.Stdin,
		Out:    os.Stdout,
		ErrOut: os.Stderr,
	}

	// Create kubectl client and get the explain command directly
	client := kubectl.NewClient(ioStreams)
	explainCmd := client.CreateExplainCommand(kubeconfigPath)

	return explainCmd
}
